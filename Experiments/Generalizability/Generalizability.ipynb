{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gopik\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\gopik\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "#from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "import torchbearer\n",
    "\n",
    "import os\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "#import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"Topological-CNN/../../../\")\n",
    "import klein\n",
    "from models import NOL_NOL , KF_NOL, CF_NOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters from original report\n",
    "conv_slices = 2\n",
    "kernel_size = 3\n",
    "batch_size = 100\n",
    "epochs = 5\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: is it meant to train and test per batch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, data_tr_loader, lr=1e-5, epochs=5, model_path='model.pth', optimizer_path='optimizer.pth'  ):\n",
    "    # https://nextjournal.com/gkoehler/pytorch-mnist\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "    #TODO:\n",
    "    log_interval = 10\n",
    "    for epoch in range(epochs):\n",
    "        network.train()\n",
    "        for batch_idx, (data, target) in enumerate(data_tr_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data)\n",
    "            #loss = torch.nn.functional.mse_loss\n",
    "            #loss = torch.nn.MSELoss(output, target)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                    torch.save(network.state_dict(), model_path)\n",
    "                    torch.save(optimizer.state_dict(), optimizer_path)\n",
    "        print('Training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network,data_test_loader, model_path='model.pth', optimizer_path='optimizer.pth'):\n",
    "    network.load_state_dict(torch.load(model_path))\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    accuracies = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_test_loader):\n",
    "            output = network(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            #accuracy = 100.0 * correct / len(data_test_loader.dataset)\n",
    "            #print(correct)\n",
    "        #print(100. * correct / len(data_test_loader.dataset))\n",
    "    print('Testing complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train2(network, data_tr_loader, lr=1e-5, epochs=5):\n",
    "#     # define the loss function and the optimiser\n",
    "#     loss_function = nn.torch.nn.MSELoss()\n",
    "#     optimiser = optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "#     # Construct a trial object with the model, optimiser and loss.\n",
    "#     # Also specify metrics we wish to compute.\n",
    "#     trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy'])\n",
    "    \n",
    "#     # Provide the data to the trial\n",
    "#     trial.with_generators(trainloader, test_generator=testloader)\n",
    "\n",
    "#     # Run  epochs of training\n",
    "#     trial.run(epochs)\n",
    "\n",
    "#     # test the performance\n",
    "#     results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
    "#     print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test2(network, data_test_loader):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVHN & MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MINST(download=False):\n",
    "    trainset = datasets.MNIST(\".\", train=True, download=download,\n",
    "                           transform=transforms.Compose([transforms.ToTensor()]))\n",
    "    testset = datasets.MNIST(\".\", train=False, download=download,\n",
    "                          transform=transforms.Compose([transforms.ToTensor()]))\n",
    "    return ConcatDataset([trainset, testset]) # 70000 samples\n",
    "mnist = torch.utils.data.DataLoader(load_MINST(), batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_SVHN(download=False):\n",
    "    svhn_transform = transforms.Compose([\n",
    "        transforms.Resize([28, 28]),  # down-resolve from (32 x 32) to (28 x 28)\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    trainset = datasets.SVHN('SVHN/', split='train', download=download,\n",
    "                             transform=svhn_transform)\n",
    "    testset = datasets.SVHN('SVHN/', split='test', download=download,\n",
    "                            transform=svhn_transform)\n",
    "    return ConcatDataset([trainset, testset])\n",
    "svhn = torch.utils.data.DataLoader(load_SVHN(), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVHN to MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "nol_nol = NOL_NOL(conv_slices, kernel_size, 10, (28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "train(nol_nol, svhn, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(nol_nol,mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MNIST to SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = NOL_NOL(conv_slices, kernel_size, 10, (28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle & CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR to KAGGLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KAGGLE to CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
