{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "# from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "# from keras.utils import np_utils\n",
    "# from skimage.transform import resize   # for resizing images\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random as rnd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "datadir = \"/home/ephy/Projects/tda_convolve_video/data/\"\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "device='cuda:0'\n",
    "\n",
    "from scipy.integrate import quad\n",
    "from scipy.integrate import dblquad\n",
    "from scipy.integrate import tplquad\n",
    "from scipy.ndimage import rotate as scipy_rotate\n",
    "from scipy.ndimage import shift as scipy_shift\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allVids = pd.read_csv(datadir + 'altered/all_data_guide_FFR.csv')\n",
    "allVids = allVids.sort_values(by=['clip', 'frame'])\n",
    "allVids_dedup = allVids.drop_duplicates(subset=['clip'], keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an interger based class to make tracking tests more simple\n",
    "classXwalk = pd.DataFrame({'class': np.unique(allVids_dedup['class'])})\n",
    "classXwalk['ind'] = np.array(list(range(0,101)))\n",
    "allVids_dedup['class_int'] = [int(classXwalk['ind'][classXwalk['class']==c]) for c in allVids_dedup['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image = np.load('/home/ephy/Projects/tda_convolve_video/data/altered/allVidStack100x100_FFR_13frames.npy', allow_pickle=True)\n",
    "all_image = all_image[:,0:9,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters0 = np.load('/home/ephy/Projects/tda_convolve_video/src/python3//KleinFeatures_55.npy', allow_pickle=True)\n",
    "filters0 = filters0.reshape(64,1,1,7,7)\n",
    "filters = np.load('/home/ephy/Projects/tda_convolve_video/src/python3/VideoFeatures_355_movandrot.npy', allow_pickle=True)\n",
    "filters77 = np.load('/home/ephy/Projects/tda_convolve_video/src/python3/VideoFeatures_377_movAndRot180.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, X, y, batchSize):\n",
    "    confusionMatrix = np.zeros([101,101], dtype=np.int8)\n",
    "    testingSeq = list(range(0,y.shape[0]+1,batchSize))\n",
    "    testingSeq.append(y.shape[0]+1)\n",
    "    testingSeq = np.array(testingSeq)\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(testingSeq)-1):\n",
    "            data = X[testingSeq[i]:testingSeq[i+1]].view(-1,1,9,100,100).to(device)\n",
    "            out = torch.argmax(net(data),axis=1).cpu()\n",
    "            yt = torch.argmax(y[testingSeq[i]:testingSeq[i+1]],axis=1)\n",
    "            for pred,label in zip(out,yt):\n",
    "                confusionMatrix[label][pred] +=1\n",
    "    del data\n",
    "    del out\n",
    "    del yt\n",
    "    return confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv3d(1, 64, (1,7,7),stride=(1,2,2))\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(64, 180, (3,5,5))\n",
    "        self.conv2 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv3 = nn.Conv3d(180, 180, (3,3,3))\n",
    "        self.conv4 = nn.Conv3d(180, 36, (1,3,3))\n",
    "        \n",
    "        x= torch.randn(1,1,9,100,100)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 400)\n",
    "        self.fc3 = nn.Linear(400, 101)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm1d(self._to_linear)\n",
    "        self.batch2 = nn.BatchNorm1d(1000)\n",
    "        self.batch3 = nn.BatchNorm1d(400)\n",
    "#         self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        \n",
    "    def convs(self, x):\n",
    "        x = F.max_pool3d(F.relu(self.conv0(x)),(1,3,3),stride=(1,2,2))\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]*x[0].shape[3]\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # reshape inside of array\n",
    "        x = self.convs(x)\n",
    "#         x = self.drop1(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "#         x = self.batch1(x)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "#         x = self.batch2(x)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.batch3(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.071360512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "torch.cuda.memory_allocated()*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Reset.\n",
      "Fold:  0 Epoch:  0\n",
      "Accuracy:  0.06301182893539581\n",
      "Fold:  0 Epoch:  1\n",
      "Accuracy:  0.08848953594176524\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-22a9dc055b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingSeq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainingSeq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrainingSeq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainingSeq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrainingSeq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "# Batch size of 26+1, because normalization requires same batch size and 4472%26=0 (very close to even split) (same logic for training)\n",
    "testingBatchSize=64\n",
    "trainingBatchSize=64\n",
    "results = [[],[],[]]\n",
    "lossrec = [[],[],[]]\n",
    "\n",
    "classMat = np.eye(101,dtype=np.float)\n",
    "\n",
    "foldIndex=0\n",
    "\n",
    "# net = Net().to(device)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "# Set filters in 2 layers\n",
    "with torch.no_grad():\n",
    "    for i,weights in enumerate(filters0):\n",
    "        net.conv0.weight[i][0] = torch.nn.Parameter(torch.tensor(weights)).to(device)\n",
    "    net.conv0.requires_grad=False\n",
    "\n",
    "print('Network Reset.')\n",
    "\n",
    "# ## Check our work\n",
    "# with torch.no_grad():\n",
    "#     for i,weights in enumerate(flat_filters):\n",
    "#         print(net.conv0.weight.shape)\n",
    "#         plt.imshow(net.conv0.weight[i][0][0].cpu(), cmap='gray')\n",
    "#         plt.show\n",
    "#         break        \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.stack(all_image), allVids_dedup['class_int'],\n",
    "                                                    shuffle=True, random_state=foldIndex,\n",
    "                                                    test_size=0.33, stratify = allVids_dedup['class_int'])\n",
    "\n",
    "\n",
    "y_train = torch.tensor([classMat[c] for c in y_train],dtype=torch.float32)\n",
    "y_test = torch.tensor([classMat[c] for c in y_test],dtype=torch.float32)\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test =  torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train),dtype=torch.float32)\n",
    "y_test = torch.tensor(np.array(y_test),dtype=torch.float32)\n",
    "\n",
    "trainingSeq = list(range(0,y_train.shape[0],trainingBatchSize))\n",
    "trainingSeq.append(y_train.shape[0]+1)\n",
    "trainingSeq = np.array(trainingSeq)\n",
    "\n",
    "# Grab 5 tests in final epoch (4 + last one run after training loop)\n",
    "finalEpochTests = list(range(int((len(trainingSeq)-1)/5),len(trainingSeq)-1,int((len(trainingSeq)-1)/5)))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(len(trainingSeq)-1):\n",
    "        X=X_train[trainingSeq[i]:trainingSeq[i+1]].view(-1,1,9,100,100)\n",
    "        X=X.to(device)\n",
    "        y=y_train[trainingSeq[i]:trainingSeq[i+1]]\n",
    "        y=y.to(device)\n",
    "        net.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = nn.CrossEntropyLoss()(output, torch.argmax(y, axis=1))\n",
    "        lossrec[foldIndex].append(float(loss.tolist()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del loss\n",
    "        del output\n",
    "        del X\n",
    "        del y\n",
    "        if epoch==(EPOCHS-1) and (i in finalEpochTests):\n",
    "            print(foldIndex,'Final Epoch',i)\n",
    "            results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "    print('Fold: ', foldIndex, 'Epoch: ',epoch)\n",
    "    results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "    cm = results[foldIndex][len(results[foldIndex])-1]\n",
    "    print('Accuracy: ' , np.sum(np.diag(cm))/np.sum(cm))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "torch.cuda.memory_allocated()*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "# Batch size of 26+1, because normalization requires same batch size and 4472%26=0 (very close to even split) (same logic for training)\n",
    "testingBatchSize=64\n",
    "trainingBatchSize=64\n",
    "results = [[],[],[]]\n",
    "lossrec = [[],[],[]]\n",
    "\n",
    "classMat = np.eye(101,dtype=np.float)\n",
    "\n",
    "foldIndex=0\n",
    "\n",
    "# net = Net().to(device)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "# Set filters in 2 layers\n",
    "with torch.no_grad():\n",
    "    for i,weights in enumerate(filters0):\n",
    "        net.conv0.weight[i][0] = torch.nn.Parameter(torch.tensor(weights)).to(device)\n",
    "    net.conv0.requires_grad=False\n",
    "    for i,weights in enumerate(flat_filters):\n",
    "        net.conv1.weight[i] = torch.nn.Parameter(torch.tensor(weights)).to(device)\n",
    "    net.conv1.requires_grad=False\n",
    "\n",
    "print('Network Reset.')\n",
    "\n",
    "# ## Check our work\n",
    "# with torch.no_grad():\n",
    "#     for i,weights in enumerate(flat_filters):\n",
    "#         plt.imshow(net.conv1.weight[i,63,2].cpu(), cmap='gray')\n",
    "#         plt.show()\n",
    "#         break        \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.stack(all_image), allVids_dedup['class_int'],\n",
    "                                                    shuffle=True, random_state=foldIndex,\n",
    "                                                    test_size=0.33, stratify = allVids_dedup['class_int'])\n",
    "\n",
    "\n",
    "y_train = torch.tensor([classMat[c] for c in y_train],dtype=torch.float32)\n",
    "y_test = torch.tensor([classMat[c] for c in y_test],dtype=torch.float32)\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test =  torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train),dtype=torch.float32)\n",
    "y_test = torch.tensor(np.array(y_test),dtype=torch.float32)\n",
    "\n",
    "trainingSeq = list(range(0,y_train.shape[0],trainingBatchSize))\n",
    "trainingSeq.append(y_train.shape[0]+1)\n",
    "trainingSeq = np.array(trainingSeq)\n",
    "\n",
    "# Grab 5 tests in final epoch (4 + last one run after training loop)\n",
    "finalEpochTests = list(range(int((len(trainingSeq)-1)/5),len(trainingSeq)-1,int((len(trainingSeq)-1)/5)))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(len(trainingSeq)-1):\n",
    "        X=X_train[trainingSeq[i]:trainingSeq[i+1]].view(-1,1,9,100,100)\n",
    "        X=X.to(device)\n",
    "        y=y_train[trainingSeq[i]:trainingSeq[i+1]]\n",
    "        y=y.to(device)\n",
    "        net.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = nn.CrossEntropyLoss()(output, torch.argmax(y, axis=1))\n",
    "        lossrec[foldIndex].append(float(loss.tolist()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del loss\n",
    "        del output\n",
    "        del X\n",
    "        del y\n",
    "        if epoch==(EPOCHS-1) and (i in finalEpochTests):\n",
    "            print(foldIndex,'Final Epoch',i)\n",
    "            results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "    print('Fold: ', foldIndex, 'Epoch: ',epoch)\n",
    "    results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "    cm = results[foldIndex][len(results[foldIndex])-1]\n",
    "    print('Accuracy: ' , np.sum(np.diag(cm))/np.sum(cm))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(1, 320, (3,7,7),stride=(1,2,2),bias=False)\n",
    "        self.conv2 = nn.Conv3d(320, 180, (3,5,5))\n",
    "        self.conv3 = nn.Conv3d(180, 180, (3,3,3))\n",
    "        self.conv4 = nn.Conv3d(180, 180, (1,3,3))\n",
    "        self.conv5 = nn.Conv3d(180, 180, (1,3,3))\n",
    "        self.conv6 = nn.Conv3d(180, 180, (1,3,3))\n",
    "        self.conv7 = nn.Conv3d(180, 180, (1,3,3))\n",
    "        \n",
    "        x= torch.randn(1,1,9,100,100)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 400)\n",
    "        self.fc3 = nn.Linear(400, 101)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm1d(self._to_linear)\n",
    "        self.batch2 = nn.BatchNorm1d(1000)\n",
    "        self.batch3 = nn.BatchNorm1d(400)\n",
    "#         self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        \n",
    "    def convs(self, x):\n",
    "        x = F.max_pool3d(F.relu(self.conv1(x)),(1,3,3),stride=(1,2,2))        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]*x[0].shape[3]\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # reshape inside of array\n",
    "        x = self.convs(x)\n",
    "#         x = self.drop1(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "#         x = self.batch1(x)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "#         x = self.batch2(x)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.batch3(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "torch.cuda.memory_allocated()*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out with bathcnorms\n",
    "# Try this out with higher resolution and proper aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "# Batch size of 26+1, because normalization requires same batch size and 4472%26=0 (very close to even split) (same logic for training)\n",
    "testingBatchSize=60\n",
    "trainingBatchSize=60\n",
    "results = [[],[],[]]\n",
    "lossrec = [[],[],[]]\n",
    "\n",
    "classMat = np.eye(101,dtype=np.float)\n",
    "\n",
    "foldIndex=0\n",
    "\n",
    "# net = Net().to(device)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "# Set filters in 2 layers\n",
    "with torch.no_grad():\n",
    "    for i,weights in enumerate(filters77):\n",
    "        net.conv1.weight[i] = torch.nn.Parameter(torch.tensor(weights)).to(device)\n",
    "    net.conv1.requires_grad=False\n",
    "\n",
    "print('Network Reset.')\n",
    "\n",
    "# ## Check our work\n",
    "# with torch.no_grad():\n",
    "#     for i,weights in enumerate(flat_filters):\n",
    "#         plt.imshow(net.conv1.weight[2,0,2].cpu(), cmap='gray')\n",
    "#         plt.show()\n",
    "#         break        \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.stack(all_image), allVids_dedup['class_int'],\n",
    "                                                    shuffle=True, random_state=foldIndex,\n",
    "                                                    test_size=0.33, stratify = allVids_dedup['class_int'])\n",
    "\n",
    "\n",
    "y_train = torch.tensor([classMat[c] for c in y_train],dtype=torch.float32)\n",
    "y_test = torch.tensor([classMat[c] for c in y_test],dtype=torch.float32)\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test =  torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train),dtype=torch.float32)\n",
    "y_test = torch.tensor(np.array(y_test),dtype=torch.float32)\n",
    "\n",
    "trainingSeq = list(range(0,y_train.shape[0],trainingBatchSize))\n",
    "trainingSeq.append(y_train.shape[0]+1)\n",
    "trainingSeq = np.array(trainingSeq)\n",
    "\n",
    "# Grab 5 tests in final epoch (4 + last one run after training loop)\n",
    "finalEpochTests = list(range(int((len(trainingSeq)-1)/5),len(trainingSeq)-1,int((len(trainingSeq)-1)/5)))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(len(trainingSeq)-1):\n",
    "        X=X_train[trainingSeq[i]:trainingSeq[i+1]].view(-1,1,9,100,100)\n",
    "        X=X.to(device)\n",
    "        y=y_train[trainingSeq[i]:trainingSeq[i+1]]\n",
    "        y=y.to(device)\n",
    "        net.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = nn.CrossEntropyLoss()(output, torch.argmax(y, axis=1))\n",
    "        lossrec[foldIndex].append(float(loss.tolist()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del loss\n",
    "        del output\n",
    "        del X\n",
    "        del y\n",
    "        if epoch==(EPOCHS-1) and (i in finalEpochTests):\n",
    "            print(foldIndex,'Final Epoch',i)\n",
    "            results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "    print('Fold: ', foldIndex, 'Epoch: ',epoch)\n",
    "    results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "    cm = results[foldIndex][len(results[foldIndex])-1]\n",
    "    print('Accuracy: ' , np.sum(np.diag(cm))/np.sum(cm))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convRescale = nn.Conv3d(1, 180, (3,7,7))\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv2 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv3 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv4 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv5 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv6 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv7 = nn.Conv3d(180, 75, (3,5,5))\n",
    "        \n",
    "        self.batchConv1 = nn.BatchNorm3d(180)\n",
    "        self.batchConv2 = nn.BatchNorm3d(180)\n",
    "        self.batchConv3 = nn.BatchNorm3d(180)\n",
    "        self.batchConv4 = nn.BatchNorm3d(180)\n",
    "        self.batchConv5 = nn.BatchNorm3d(75)\n",
    "        \n",
    "        self.up = nn.Upsample((7,31,31),mode='trilinear',align_corners=False)\n",
    "        \n",
    "        x= torch.randn(1,1,9,100,100)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 700)\n",
    "        self.fc2 = nn.Linear(700, 200)\n",
    "        self.fc3 = nn.Linear(200, 101)        \n",
    "        \n",
    "        self.batch1 = nn.BatchNorm1d(self._to_linear)\n",
    "        self.batch2 = nn.BatchNorm1d(750)\n",
    "        self.batch3 = nn.BatchNorm1d(200)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        \n",
    "    def convs(self, x):\n",
    "        x = F.max_pool3d(self.convRescale(x),(1,3,3))\n",
    "        x = self.batchConv1(x)\n",
    "        inp1 = x\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batchConv2(x)\n",
    "        x = self.up(x)\n",
    "        inp2 = x\n",
    "        x+=inp1\n",
    "        del inp1\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.batchConv3(x)\n",
    "        x = self.up(x)\n",
    "        inp1 = x\n",
    "        x+=inp2\n",
    "        del inp2\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.batchConv4(x)\n",
    "        x = self.up(x)\n",
    "        x+=inp1\n",
    "        del inp1\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.batchConv5(x)\n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]*x[0].shape[3]\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.batch3(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "torch.cuda.memory_allocated()*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters77 = np.load('/home/ephy/Projects/tda_convolve_video/src/python3/VideoFeatures_377_movAndRot180.npy', allow_pickle=True)\n",
    "filters77.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "# Batch size of 26+1, because normalization requires same batch size and 4472%26=0 (very close to even split) (same logic for training)\n",
    "testingBatchSize=30\n",
    "trainingBatchSize=30\n",
    "results = [[],[],[]]\n",
    "lossrec = [[],[],[]]\n",
    "\n",
    "classMat = np.eye(101,dtype=np.float)\n",
    "\n",
    "foldIndex=0\n",
    "\n",
    "# net = Net().to(device)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "# Set filters in 2 layers\n",
    "with torch.no_grad():\n",
    "    for i,weights in enumerate(filters77):\n",
    "        net.convRescale.weight[i] = torch.nn.Parameter(torch.tensor(weights)).to(device)\n",
    "    net.conv1.requires_grad=False\n",
    "\n",
    "print('Network Reset.')\n",
    "\n",
    "# ## Check our work\n",
    "# with torch.no_grad():\n",
    "#     for i,weights in enumerate(flat_filters):\n",
    "#         plt.imshow(net.conv1.weight[2,0,2].cpu(), cmap='gray')\n",
    "#         plt.show()\n",
    "#         break        \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.stack(all_image), allVids_dedup['class_int'],\n",
    "                                                    shuffle=True, random_state=foldIndex,\n",
    "                                                    test_size=0.33, stratify = allVids_dedup['class_int'])\n",
    "\n",
    "\n",
    "y_train = torch.tensor([classMat[c] for c in y_train],dtype=torch.float32)\n",
    "y_test = torch.tensor([classMat[c] for c in y_test],dtype=torch.float32)\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test =  torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train),dtype=torch.float32)\n",
    "y_test = torch.tensor(np.array(y_test),dtype=torch.float32)\n",
    "\n",
    "trainingSeq = list(range(0,y_train.shape[0],trainingBatchSize))\n",
    "trainingSeq.append(y_train.shape[0]+1)\n",
    "trainingSeq = np.array(trainingSeq)\n",
    "\n",
    "# Grab 5 tests in final epoch (4 + last one run after training loop)\n",
    "finalEpochTests = list(range(int((len(trainingSeq)-1)/5),len(trainingSeq)-1,int((len(trainingSeq)-1)/5)))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(len(trainingSeq)-1):\n",
    "        X=X_train[trainingSeq[i]:trainingSeq[i+1]].view(-1,1,9,100,100)\n",
    "        X=X.to(device)\n",
    "        y=y_train[trainingSeq[i]:trainingSeq[i+1]]\n",
    "        y=y.to(device)\n",
    "        net.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = nn.CrossEntropyLoss()(output, torch.argmax(y, axis=1))\n",
    "        lossrec[foldIndex].append(float(loss.tolist()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del loss\n",
    "        del output\n",
    "        del X\n",
    "        del y\n",
    "        if epoch==(EPOCHS-1) and (i in finalEpochTests):\n",
    "            print(foldIndex,'Final Epoch',i)\n",
    "            results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "    print('Fold: ', foldIndex, 'Epoch: ',epoch)\n",
    "    results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "    cm = results[foldIndex][len(results[foldIndex])-1]\n",
    "    print('Accuracy: ' , np.sum(np.diag(cm))/np.sum(cm))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "# Batch size of 26+1, because normalization requires same batch size and 4472%26=0 (very close to even split) (same logic for training)\n",
    "testingBatchSize=30\n",
    "trainingBatchSize=30\n",
    "results = [[],[],[]]\n",
    "lossrec = [[],[],[]]\n",
    "\n",
    "classMat = np.eye(101,dtype=np.float)\n",
    "\n",
    "foldIndex=0\n",
    "\n",
    "# net = ResNet().to(device)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "# Set filters in 2 layers\n",
    "with torch.no_grad():\n",
    "    for i,weights in enumerate(filters77):\n",
    "        net.convRescale.weight[i] = torch.nn.Parameter(torch.tensor(weights)).to(device)\n",
    "    net.convRescale.requires_grad=False\n",
    "\n",
    "print('Network Reset.')\n",
    "\n",
    "# ## Check our work\n",
    "# with torch.no_grad():\n",
    "#     for i,weights in enumerate(flat_filters):\n",
    "#         plt.imshow(net.conv1.weight[2,0,2].cpu(), cmap='gray')\n",
    "#         plt.show()\n",
    "#         break        \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.stack(all_image), allVids_dedup['class_int'],\n",
    "                                                    shuffle=True, random_state=foldIndex,\n",
    "                                                    test_size=0.33, stratify = allVids_dedup['class_int'])\n",
    "\n",
    "\n",
    "y_train = torch.tensor([classMat[c] for c in y_train],dtype=torch.float32)\n",
    "y_test = torch.tensor([classMat[c] for c in y_test],dtype=torch.float32)\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test =  torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train),dtype=torch.float32)\n",
    "y_test = torch.tensor(np.array(y_test),dtype=torch.float32)\n",
    "\n",
    "trainingSeq = list(range(0,y_train.shape[0],trainingBatchSize))\n",
    "trainingSeq.append(y_train.shape[0]+1)\n",
    "trainingSeq = np.array(trainingSeq)\n",
    "\n",
    "# Grab 5 tests in final epoch (4 + last one run after training loop)\n",
    "finalEpochTests = list(range(int((len(trainingSeq)-1)/5),len(trainingSeq)-1,int((len(trainingSeq)-1)/5)))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(len(trainingSeq)-1):\n",
    "        X=X_train[trainingSeq[i]:trainingSeq[i+1]].view(-1,1,9,100,100)\n",
    "        X=X.to(device)\n",
    "        y=y_train[trainingSeq[i]:trainingSeq[i+1]]\n",
    "        y=y.to(device)\n",
    "        net.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = nn.CrossEntropyLoss()(output, torch.argmax(y, axis=1))\n",
    "        lossrec[foldIndex].append(float(loss.tolist()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del loss\n",
    "        del output\n",
    "        del X\n",
    "        del y\n",
    "        if epoch==(EPOCHS-1) and (i in finalEpochTests):\n",
    "            print(foldIndex,'Final Epoch',i)\n",
    "            results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "    print('Fold: ', foldIndex, 'Epoch: ',epoch)\n",
    "    results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "    cm = results[foldIndex][len(results[foldIndex])-1]\n",
    "    print('Accuracy: ' , np.sum(np.diag(cm))/np.sum(cm))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "# Batch size of 26+1, because normalization requires same batch size and 4472%26=0 (very close to even split) (same logic for training)\n",
    "testingBatchSize=30\n",
    "trainingBatchSize=30\n",
    "results = [[],[],[]]\n",
    "lossrec = [[],[],[]]\n",
    "\n",
    "classMat = np.eye(101,dtype=np.float)\n",
    "\n",
    "for foldIndex in range(3):\n",
    "\n",
    "    net = ResNet().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=5e-6)\n",
    "\n",
    "    # Set filters in 2 layers\n",
    "    with torch.no_grad():\n",
    "        for i,weights in enumerate(filters77):\n",
    "            net.convRescale.weight[i] = torch.nn.Parameter(torch.tensor(weights)).to(device)\n",
    "        net.convRescale.requires_grad=False\n",
    "\n",
    "    print('Network Reset.')\n",
    "\n",
    "    # ## Check our work\n",
    "    # with torch.no_grad():\n",
    "    #     for i,weights in enumerate(flat_filters):\n",
    "    #         plt.imshow(net.conv1.weight[2,0,2].cpu(), cmap='gray')\n",
    "    #         plt.show()\n",
    "    #         break        \n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.stack(all_image), allVids_dedup['class_int'],\n",
    "                                                        shuffle=True, random_state=foldIndex,\n",
    "                                                        test_size=0.33, stratify = allVids_dedup['class_int'])\n",
    "\n",
    "\n",
    "    y_train = torch.tensor([classMat[c] for c in y_train],dtype=torch.float32)\n",
    "    y_test = torch.tensor([classMat[c] for c in y_test],dtype=torch.float32)\n",
    "    X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "    X_test =  torch.tensor(X_test,dtype=torch.float32)\n",
    "    y_train = torch.tensor(np.array(y_train),dtype=torch.float32)\n",
    "    y_test = torch.tensor(np.array(y_test),dtype=torch.float32)\n",
    "\n",
    "    trainingSeq = list(range(0,y_train.shape[0],trainingBatchSize))\n",
    "    trainingSeq.append(y_train.shape[0]+1)\n",
    "    trainingSeq = np.array(trainingSeq)\n",
    "\n",
    "    # Grab 5 tests in final epoch (4 + last one run after training loop)\n",
    "    finalEpochTests = list(range(int((len(trainingSeq)-1)/5),len(trainingSeq)-1,int((len(trainingSeq)-1)/5)))\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in range(len(trainingSeq)-1):\n",
    "            X=X_train[trainingSeq[i]:trainingSeq[i+1]].view(-1,1,9,100,100)\n",
    "            X=X.to(device)\n",
    "            y=y_train[trainingSeq[i]:trainingSeq[i+1]]\n",
    "            y=y.to(device)\n",
    "            net.zero_grad()\n",
    "            output = net(X)\n",
    "            loss = nn.CrossEntropyLoss()(output, torch.argmax(y, axis=1))\n",
    "            lossrec[foldIndex].append(float(loss.tolist()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "            del output\n",
    "            del X\n",
    "            del y\n",
    "#             if epoch==(EPOCHS-1) and (i in finalEpochTests):\n",
    "#                 print(foldIndex,'Final Epoch',i)\n",
    "#                 results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "        print('Fold: ', foldIndex, 'Epoch: ',epoch)\n",
    "        results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "        cm = results[foldIndex][len(results[foldIndex])-1]\n",
    "        print('Accuracy: ' , np.sum(np.diag(cm))/np.sum(cm))\n",
    "\n",
    "np.save('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_k1layer_30_res.npy', results)\n",
    "np.save('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_k1layer_30_loss.npy', lossrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normRes = np.load('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_normal_res.npy', allow_pickle=True)\n",
    "normLoss = np.load('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_normal_loss.npy', allow_pickle=True)\n",
    "\n",
    "a = np.array([[np.sum(np.diag(cm))/np.sum(cm) for cm in result] for result in normRes])\n",
    "\n",
    "plt.plot(np.mean(a,axis=0))\n",
    "plt.plot(np.mean(a,axis=0)-np.std(a, axis=0),color='gray', linestyle='--')\n",
    "plt.plot(np.mean(a,axis=0)+np.std(a, axis=0),color='gray', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "# Batch size of 26+1, because normalization requires same batch size and 4472%26=0 (very close to even split) (same logic for training)\n",
    "testingBatchSize=30\n",
    "trainingBatchSize=30\n",
    "# results = [[],[],[]]\n",
    "# lossrec = [[],[],[]]\n",
    "\n",
    "# SWITCHED ON FIRST LAYER AT 27 E\n",
    "\n",
    "classMat = np.eye(101,dtype=np.float)\n",
    "\n",
    "for foldIndex in range(3):\n",
    "\n",
    "    net = ResNet().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "#     #Set filters in 2 layers\n",
    "#     with torch.no_grad():\n",
    "#         for i,weights in enumerate(filters77):\n",
    "#             net.convRescale.weight[i] = torch.nn.Parameter(torch.tensor(weights)).to(device)\n",
    "#         net.convRescale.requires_grad=False\n",
    "\n",
    "    print('Network Reset.')\n",
    "\n",
    "    # ## Check our work\n",
    "    # with torch.no_grad():\n",
    "    #     for i,weights in enumerate(flat_filters):\n",
    "    #         plt.imshow(net.conv1.weight[2,0,2].cpu(), cmap='gray')\n",
    "    #         plt.show()\n",
    "    #         break        \n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.stack(all_image), allVids_dedup['class_int'],\n",
    "                                                        shuffle=True, random_state=foldIndex,\n",
    "                                                        test_size=0.33, stratify = allVids_dedup['class_int'])\n",
    "\n",
    "\n",
    "    y_train = torch.tensor([classMat[c] for c in y_train],dtype=torch.float32)\n",
    "    y_test = torch.tensor([classMat[c] for c in y_test],dtype=torch.float32)\n",
    "    X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "    X_test =  torch.tensor(X_test,dtype=torch.float32)\n",
    "    y_train = torch.tensor(np.array(y_train),dtype=torch.float32)\n",
    "    y_test = torch.tensor(np.array(y_test),dtype=torch.float32)\n",
    "\n",
    "    trainingSeq = list(range(0,y_train.shape[0],trainingBatchSize))\n",
    "    trainingSeq.append(y_train.shape[0]+1)\n",
    "    trainingSeq = np.array(trainingSeq)\n",
    "\n",
    "    # Grab 5 tests in final epoch (4 + last one run after training loop)\n",
    "    finalEpochTests = list(range(int((len(trainingSeq)-1)/5),len(trainingSeq)-1,int((len(trainingSeq)-1)/5)))\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in range(len(trainingSeq)-1):\n",
    "            X=X_train[trainingSeq[i]:trainingSeq[i+1]].view(-1,1,9,100,100)\n",
    "            X=X.to(device)\n",
    "            y=y_train[trainingSeq[i]:trainingSeq[i+1]]\n",
    "            y=y.to(device)\n",
    "            net.zero_grad()\n",
    "            output = net(X)\n",
    "            loss = nn.CrossEntropyLoss()(output, torch.argmax(y, axis=1))\n",
    "            lossrec[foldIndex].append(float(loss.tolist()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "            del output\n",
    "            del X\n",
    "            del y\n",
    "#             if epoch==(EPOCHS-1) and (i in finalEpochTests):\n",
    "#                 print(foldIndex,'Final Epoch',i)\n",
    "#                 results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "        print('Fold: ', foldIndex, 'Epoch: ',epoch)\n",
    "        results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "        cm = results[foldIndex][len(results[foldIndex])-1]\n",
    "        print('Accuracy: ' , np.sum(np.diag(cm))/np.sum(cm))\n",
    "\n",
    "np.save('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_normal_res_30.npy', results)\n",
    "np.save('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_normal_loss_30.npy', lossrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normRes = np.load('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_normal_res.npy', allow_pickle=True)\n",
    "normLoss = np.load('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_normal_loss.npy', allow_pickle=True)\n",
    "\n",
    "a = np.array([[np.sum(np.diag(cm))/np.sum(cm) for cm in result] for result in normRes])\n",
    "\n",
    "k1Res = np.load('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_l1klein_res.npy', allow_pickle=True)\n",
    "k1Loss = np.load('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_l1klein_res.npy', allow_pickle=True)\n",
    "\n",
    "b = np.array([[np.sum(np.diag(cm))/np.sum(cm) for cm in result] for result in k1Res])\n",
    "\n",
    "plt.plot(np.mean(b,axis=0), label='Trans/Rotate Klein 1st Layer')\n",
    "plt.plot(np.mean(b,axis=0)-2*np.std(b, axis=0),color='gray', linestyle='--')\n",
    "plt.plot(np.mean(b,axis=0)+2*np.std(b, axis=0),color='gray', linestyle='--')\n",
    "\n",
    "plt.plot(np.mean(a,axis=0), label='Normal')\n",
    "plt.plot(np.mean(a,axis=0)-2*np.std(a, axis=0),color='gray', linestyle='--')\n",
    "plt.plot(np.mean(a,axis=0)+2*np.std(a, axis=0),color='gray', linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Tangent Klein 1st Layer vs Randomly Instantiated 8-layer ResNet')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "normRes30 = np.load('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_normal_res_30.npy', allow_pickle=True)\n",
    "\n",
    "normRes30[0] = normRes30[0][29:]\n",
    "\n",
    "a = np.array([[np.sum(np.diag(cm))/np.sum(cm) for cm in result] for result in normRes30])\n",
    "\n",
    "k1Res = np.load('/home/ephy/Projects/tda_convolve_video/data/altered/resnet8_k1layer_30_res.npy', allow_pickle=True)\n",
    "\n",
    "b = np.array([[np.sum(np.diag(cm))/np.sum(cm) for cm in result] for result in k1Res])\n",
    "\n",
    "plt.plot(np.mean(b,axis=0), label='Trans/Rotate Klein 1st Layer')\n",
    "plt.plot(np.mean(b,axis=0)-2*np.std(b, axis=0),color='gray', linestyle='--')\n",
    "plt.plot(np.mean(b,axis=0)+2*np.std(b, axis=0),color='gray', linestyle='--')\n",
    "\n",
    "plt.plot(np.mean(a,axis=0), label='Normal')\n",
    "plt.plot(np.mean(a,axis=0)-2*np.std(a, axis=0),color='gray', linestyle='--')\n",
    "plt.plot(np.mean(a,axis=0)+2*np.std(a, axis=0),color='gray', linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Tangent Klein 1st Layer vs Randomly Instantiated 8-layer ResNet')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convRescale = nn.Conv3d(1, 180, (3,7,7))\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv2 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv3 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv4 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv5 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv6 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv7 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv8 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv9 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv10 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv11 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv12 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv13 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv14 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv15 = nn.Conv3d(180, 75, (3,5,5))\n",
    "\n",
    "        \n",
    "        self.batchConv1 = nn.BatchNorm3d(180)\n",
    "        self.batchConv2 = nn.BatchNorm3d(180)\n",
    "        self.batchConv3 = nn.BatchNorm3d(180)\n",
    "        self.batchConv4 = nn.BatchNorm3d(180)\n",
    "        self.batchConv5 = nn.BatchNorm3d(180)\n",
    "        self.batchConv6 = nn.BatchNorm3d(180)\n",
    "        self.batchConv7 = nn.BatchNorm3d(180)\n",
    "        self.batchConv8 = nn.BatchNorm3d(75)\n",
    "        \n",
    "        self.up = nn.Upsample((7,31,31),mode='trilinear',align_corners=False)\n",
    "        \n",
    "        x= torch.randn(1,1,9,100,100)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 700)\n",
    "        self.fc2 = nn.Linear(700, 200)\n",
    "        self.fc3 = nn.Linear(200, 101)        \n",
    "        \n",
    "        self.batch1 = nn.BatchNorm1d(self._to_linear)\n",
    "        self.batch2 = nn.BatchNorm1d(750)\n",
    "        self.batch3 = nn.BatchNorm1d(200)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        \n",
    "    def convs(self, x):\n",
    "        x = F.max_pool3d(self.convRescale(x),(1,3,3))\n",
    "        inp1 = x\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batchConv1(x)\n",
    "        x = self.up(x)\n",
    "        inp2 = x\n",
    "        x+=inp1\n",
    "        del inp1\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.batchConv2(x)\n",
    "        x = self.up(x)\n",
    "        inp1 = x\n",
    "        x+=inp2\n",
    "        del inp2\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.batchConv3(x)\n",
    "        x = self.up(x)\n",
    "        inp2 = x\n",
    "        x+=inp1\n",
    "        del inp1\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = self.batchConv4(x)\n",
    "        x = self.up(x)\n",
    "        inp1 = x\n",
    "        x+=inp2\n",
    "        del inp2\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = self.batchConv5(x)\n",
    "        x = self.up(x)\n",
    "        inp2 = x\n",
    "        x+=inp1\n",
    "        del inp1\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = self.batchConv6(x)\n",
    "        x = self.up(x)\n",
    "        inp1 = x\n",
    "        x+=inp2\n",
    "        del inp2\n",
    "        x = F.relu(self.conv13(x))\n",
    "        x = F.relu(self.conv14(x))\n",
    "        x = self.batchConv7(x)\n",
    "        x = self.up(x)\n",
    "        x+=inp1\n",
    "        del inp1  \n",
    "        x = F.relu(self.conv15(x))\n",
    "        x = self.batchConv8(x)\n",
    "                \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]*x[0].shape[3]\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.batch3(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BigResNet().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "torch.cuda.memory_allocated()*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters55 = np.load('/home/ephy/Projects/tda_convolve_video/src/python3/VideoFeatures_355_movandrot.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with small-ish net with klein features in first layer of first block as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "# Batch size of 26+1, because normalization requires same batch size and 4472%26=0 (very close to even split) (same logic for training)\n",
    "testingBatchSize=30\n",
    "trainingBatchSize=30\n",
    "results = [[],[],[]]\n",
    "lossrec = [[],[],[]]\n",
    "\n",
    "# SWITCHED ON FIRST LAYER AT 27 E\n",
    "\n",
    "classMat = np.eye(101,dtype=np.float)\n",
    "\n",
    "for foldIndex in range(3):\n",
    "\n",
    "    net = ResNet().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "#     #Set filters in 2 layers\n",
    "    with torch.no_grad():\n",
    "        for i,weights in enumerate(filters77):\n",
    "            net.convRescale.weight[i] = torch.nn.Parameter(torch.tensor(weights)).to(device)\n",
    "        net.convRescale.requires_grad=False\n",
    "        for i,weights in enumerate(filters55):\n",
    "            net.conv1.weight[i] = torch.nn.Parameter(torch.tensor(filters55)).to(device)\n",
    "        net.conv1.requires_grad=False        \n",
    "\n",
    "    print('Network Reset.')\n",
    "\n",
    "    # ## Check our work\n",
    "    # with torch.no_grad():\n",
    "    #     for i,weights in enumerate(flat_filters):\n",
    "    #         plt.imshow(net.conv1.weight[2,0,2].cpu(), cmap='gray')\n",
    "    #         plt.show()\n",
    "    #         break        \n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.stack(all_image), allVids_dedup['class_int'],\n",
    "                                                        shuffle=True, random_state=foldIndex,\n",
    "                                                        test_size=0.33, stratify = allVids_dedup['class_int'])\n",
    "\n",
    "\n",
    "    y_train = torch.tensor([classMat[c] for c in y_train],dtype=torch.float32)\n",
    "    y_test = torch.tensor([classMat[c] for c in y_test],dtype=torch.float32)\n",
    "    X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "    X_test =  torch.tensor(X_test,dtype=torch.float32)\n",
    "    y_train = torch.tensor(np.array(y_train),dtype=torch.float32)\n",
    "    y_test = torch.tensor(np.array(y_test),dtype=torch.float32)\n",
    "\n",
    "    trainingSeq = list(range(0,y_train.shape[0],trainingBatchSize))\n",
    "    trainingSeq.append(y_train.shape[0]+1)\n",
    "    trainingSeq = np.array(trainingSeq)\n",
    "\n",
    "    # Grab 5 tests in final epoch (4 + last one run after training loop)\n",
    "    finalEpochTests = list(range(int((len(trainingSeq)-1)/5),len(trainingSeq)-1,int((len(trainingSeq)-1)/5)))\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in range(len(trainingSeq)-1):\n",
    "            X=X_train[trainingSeq[i]:trainingSeq[i+1]].view(-1,1,9,100,100)\n",
    "            X=X.to(device)\n",
    "            y=y_train[trainingSeq[i]:trainingSeq[i+1]]\n",
    "            y=y.to(device)\n",
    "            net.zero_grad()\n",
    "            output = net(X)\n",
    "            loss = nn.CrossEntropyLoss()(output, torch.argmax(y, axis=1))\n",
    "            lossrec[foldIndex].append(float(loss.tolist()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "            del output\n",
    "            del X\n",
    "            del y\n",
    "#             if epoch==(EPOCHS-1) and (i in finalEpochTests):\n",
    "#                 print(foldIndex,'Final Epoch',i)\n",
    "#                 results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "        print('Fold: ', foldIndex, 'Epoch: ',epoch)\n",
    "        results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "        cm = results[foldIndex][len(results[foldIndex])-1]\n",
    "        print('Accuracy: ' , np.sum(np.diag(cm))/np.sum(cm))\n",
    "\n",
    "np.save('/home/ephy/Projects/tda_convolve_video/data/altered/resnet16_k1layer_res_30.npy', results)\n",
    "np.save('/home/ephy/Projects/tda_convolve_video/data/altered/resnet16_k1layer_loss_30.npy', lossrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "# Batch size of 26+1, because normalization requires same batch size and 4472%26=0 (very close to even split) (same logic for training)\n",
    "testingBatchSize=30\n",
    "trainingBatchSize=30\n",
    "results = [[],[],[]]\n",
    "lossrec = [[],[],[]]\n",
    "\n",
    "# SWITCHED ON FIRST LAYER AT 27 E\n",
    "\n",
    "classMat = np.eye(101,dtype=np.float)\n",
    "\n",
    "for foldIndex in range(3):\n",
    "\n",
    "    net = ResNet().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "#     #Set filters in 2 layers\n",
    "    with torch.no_grad():\n",
    "        for i,weights in enumerate(filters77):\n",
    "            net.convRescale.weight[i] = torch.nn.Parameter(torch.tensor(weights)).to(device)\n",
    "        net.convRescale.requires_grad=False\n",
    "#         for i,weights in enumerate(filters55):\n",
    "#             net.conv1.weight[i] = torch.nn.Parameter(torch.tensor(filters55)).to(device)\n",
    "#         net.conv1.requires_grad=False        \n",
    "\n",
    "    print('Network Reset.')\n",
    "\n",
    "    # ## Check our work\n",
    "    # with torch.no_grad():\n",
    "    #     for i,weights in enumerate(flat_filters):\n",
    "    #         plt.imshow(net.conv1.weight[2,0,2].cpu(), cmap='gray')\n",
    "    #         plt.show()\n",
    "    #         break        \n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.stack(all_image), allVids_dedup['class_int'],\n",
    "                                                        shuffle=True, random_state=foldIndex,\n",
    "                                                        test_size=0.33, stratify = allVids_dedup['class_int'])\n",
    "\n",
    "\n",
    "    y_train = torch.tensor([classMat[c] for c in y_train],dtype=torch.float32)\n",
    "    y_test = torch.tensor([classMat[c] for c in y_test],dtype=torch.float32)\n",
    "    X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "    X_test =  torch.tensor(X_test,dtype=torch.float32)\n",
    "    y_train = torch.tensor(np.array(y_train),dtype=torch.float32)\n",
    "    y_test = torch.tensor(np.array(y_test),dtype=torch.float32)\n",
    "\n",
    "    trainingSeq = list(range(0,y_train.shape[0],trainingBatchSize))\n",
    "    trainingSeq.append(y_train.shape[0]+1)\n",
    "    trainingSeq = np.array(trainingSeq)\n",
    "\n",
    "    # Grab 5 tests in final epoch (4 + last one run after training loop)\n",
    "    finalEpochTests = list(range(int((len(trainingSeq)-1)/5),len(trainingSeq)-1,int((len(trainingSeq)-1)/5)))\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in range(len(trainingSeq)-1):\n",
    "            X=X_train[trainingSeq[i]:trainingSeq[i+1]].view(-1,1,9,100,100)\n",
    "            X=X.to(device)\n",
    "            y=y_train[trainingSeq[i]:trainingSeq[i+1]]\n",
    "            y=y.to(device)\n",
    "            net.zero_grad()\n",
    "            output = net(X)\n",
    "            loss = nn.CrossEntropyLoss()(output, torch.argmax(y, axis=1))\n",
    "            lossrec[foldIndex].append(float(loss.tolist()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "            del output\n",
    "            del X\n",
    "            del y\n",
    "#             if epoch==(EPOCHS-1) and (i in finalEpochTests):\n",
    "#                 print(foldIndex,'Final Epoch',i)\n",
    "#                 results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "        print('Fold: ', foldIndex, 'Epoch: ',epoch)\n",
    "        results[foldIndex].append(test(net, X_test, y_test, testingBatchSize))\n",
    "        cm = results[foldIndex][len(results[foldIndex])-1]\n",
    "        print('Accuracy: ' , np.sum(np.diag(cm))/np.sum(cm))\n",
    "\n",
    "np.save('/home/ephy/Projects/tda_convolve_video/data/altered/resnet16_k1layer_res_30.npy', results)\n",
    "np.save('/home/ephy/Projects/tda_convolve_video/data/altered/resnet16_k1layer_loss_30.npy', lossrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
