{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "# from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "# from keras.utils import np_utils\n",
    "# from skimage.transform import resize   # for resizing images\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random as rnd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "device='cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convRe = nn.Conv3d(1, 180, (3,5,5))\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv3d(1, 180, (3,5,5))\n",
    "        self.conv2 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv3 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv4 = nn.Conv3d(180, 180, (3,5,5))\n",
    "        self.conv5 = nn.Conv3d(180, 36, (1,5,5))\n",
    "        \n",
    "        self.down1 = nn.Upsample((5,92,92),mode='trilinear')\n",
    "        self.down2 = nn.Upsample((1,84,84),mode='trilinear')\n",
    "\n",
    "        x= torch.randn(1,1,9,100,100)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 700)\n",
    "        self.fc2 = nn.Linear(700, 200)\n",
    "        self.fc3 = nn.Linear(200, 101)        \n",
    "        \n",
    "        self.batch1 = nn.BatchNorm1d(self._to_linear)\n",
    "        self.batch2 = nn.BatchNorm1d(750)\n",
    "        self.batch3 = nn.BatchNorm1d(200)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        \n",
    "    def convs(self, x):\n",
    "        inp1 = self.down1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        inp2 = self.down2(x)\n",
    "        x+=inp1\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x+=inp2\n",
    "        x = F.relu(self.conv5(x))\n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]*x[0].shape[3]\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.batch3(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.679337984"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ResNet().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "torch.cuda.memory_allocated()*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6296, 0.7037, 0.6296],\n",
       "         [0.6296, 0.7037, 0.6296]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = torch.tensor([.5,.75,.875,.75,.5], dtype=torch.float32)\n",
    "x = x.view(1,1,x.shape[0])\n",
    "layer = nn.Conv1d(1, 2,(3),bias=False)\n",
    "layer.weight = torch.nn.Parameter(torch.tensor(np.ones(layer.weight.shape),dtype=torch.float))\n",
    "layer.requires_gradient=False\n",
    "layer(x)/(torch.sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 1.5000, 1.6667, 1.5000, 1.0000],\n",
      "         [1.0000, 1.5000, 1.6667, 1.5000, 1.0000]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1.1667, 1.6667, 1.1667],\n",
       "         [1.1667, 1.6667, 1.1667]]], grad_fn=<UpsampleLinear1DBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = torch.tensor([1,2,3,4,3,2,1], dtype=torch.float32)\n",
    "x = x.view(1,1,x.shape[0])\n",
    "layer = nn.Conv1d(1, 2,(3), bias=False)\n",
    "weights=np.ones(layer.weight.shape)\n",
    "weights=weights/np.sum(weights)\n",
    "layer.weight = torch.nn.Parameter(torch.tensor(weights,dtype=torch.float))\n",
    "newX  = layer(x)\n",
    "up = nn.Upsample(3,mode='linear')\n",
    "print(newX)\n",
    "up(newX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
